{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path as osp\n",
    "import os as os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.datasets import load_digits#\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from sklearn.utils import class_weight as clsw\n",
    "from time import time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from parse_fasta import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def handle_data(df):\n",
    "    print('Shape data{}'.format(df.shape))\n",
    "    \n",
    "    # transform labels to numerical\n",
    "    y = df['label'].values\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(y)\n",
    "    y = le.transform(y)\n",
    "    \n",
    "    print('Number of unique classes and their counts {}'.format(np.unique(y, return_counts=True)))\n",
    "    #add ML ready labels to data frame\n",
    "\n",
    "    #STEP 1: remove all classes with occurences less then threshold\n",
    "    thresh = 10\n",
    "    _, counts = np.unique(y, return_counts=True)\n",
    "    mask = np.isin(y, np.where(counts >= thresh)[0])\n",
    "    print(np.sum(counts[counts < 10]) == len(df) - len(df[mask]))\n",
    "    df = df[mask]\n",
    "    \n",
    "    # STEP 2: remove datapoints where kmer frequency sum is less or equal to threshold\n",
    "    ths_kmer = 0\n",
    "    mask = np.sum(df.iloc[:, 2:].values, axis=1) > ths_kmer\n",
    "    df = df[mask]\n",
    "    print('New data shape: {}'.format(df.shape))\n",
    "    \n",
    "        \n",
    "    # transform labels to numerical\n",
    "    y = df['label'].values\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(y)\n",
    "    y = le.transform(y)\n",
    "    \n",
    "    X = df.iloc[:, 2:].values\n",
    "\n",
    "    print('New shape after removing classes{}'.format(df.shape))\n",
    "    \n",
    "    return X,y\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_benchmarks(y_test):\n",
    "    unique, counts = np.unique(y_test, return_counts=True)\n",
    "\n",
    "    #computing uniformly (random guessing) class predictions\n",
    "    n_samples = len(y_test)\n",
    "    n_classes = len(unique)\n",
    "    uniform_preds = np.random.randint(n_classes, size=n_samples)\n",
    "\n",
    "    #computing class predictions using Naive bayes(i.e. class probs from data)\n",
    "    class_probs = counts/n_samples\n",
    "    naive_preds = np.random.choice(unique, size=n_samples, p=class_probs)\n",
    "\n",
    "    return accuracy_score(y_test, uniform_preds), accuracy_score(y_test, naive_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bootstrap(clf2 ,X_test ,y_test, b):\n",
    "    '''\n",
    "    :param X: Input test data\n",
    "    :param y: test labels\n",
    "    :param b: number of bootstrap samples to draw (100-1000)\n",
    "    :return: the standard deviation (std) aver all and per class over all bootstrap samples.\n",
    "    '''\n",
    "\n",
    "    #initilize lists to store elements\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "    y_test = pd.DataFrame(y_test).iloc[:,0]\n",
    "    \n",
    "    acc_list = list()\n",
    "    classes = pd.unique(y_test)\n",
    "\n",
    "    # compute length of data set\n",
    "    n = len(X_test)\n",
    "\n",
    "    for i in range(b):\n",
    "\n",
    "        # generate random indices and draw sample\n",
    "        X_sub = X_test.sample(int(n*0.6))\n",
    "        y_sub = y_test[X_sub.index]\n",
    "\n",
    "        # compute accurace and append to list\n",
    "        acc = accuracy_score(y_sub, clf2.predict(X_sub))\n",
    "        acc_list.append(acc)\n",
    "\n",
    "\n",
    "    acc_array = np.array(acc_list)\n",
    "    sd_acc = np.std(acc_array)\n",
    "\n",
    "    return sd_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def presentation_metric(clf, X_test, y_test):\n",
    "    \n",
    "    # Evaluate model pipeline on test data\n",
    "    y_pred = clf.predict(X_test)\n",
    "    overall_acc = accuracy_score(y_test, y_pred)\n",
    "    sd_acc = bootstrap(clf, X_test, y_test, 100)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "    class_names = np.unique(y)\n",
    "    # Plot non-normalized confusion matrix\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                          title='Confusion matrix, without normalization', cmap=plt.cm.Blues)\n",
    "    \n",
    "    random, naive = random_benchmarks(y_test)\n",
    "    \n",
    "    return overall_acc, sd_acc, cnf_matrix , random , naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_opt_model(X,y):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                       test_size=0.2,random_state=7, stratify = y)\n",
    "    \n",
    "                                                    \n",
    "    #build a random forest classifier\n",
    "    clf = RandomForestClassifier(n_estimators=30,  class_weight = \"balanced_subsample\")\n",
    "\n",
    "    # specify parameters and distributions to sample from\n",
    "    param_dist = {\"max_depth\": [3, None],\n",
    "                  \"max_features\": [None, 'sqrt', 'log2'],\n",
    "                  \"min_samples_split\": sp_randint(2, 11),\n",
    "                  \"min_samples_leaf\": sp_randint(1, 11),\n",
    "                  \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "    # run randomized search\n",
    "    n_iter_search = 30\n",
    "    random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                       n_iter=n_iter_search,cv=5, verbose=1, n_jobs=64, \n",
    "                                       refit='accuracy', scoring='accuracy')\n",
    "\n",
    "    start = time()\n",
    "    random_search.fit(X_train, y_train)\n",
    "    print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "          \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "    \n",
    "    best_estimator = random_search.best_estimator_\n",
    "    \n",
    "    return best_estimator, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get reuslts presentation Eukaryots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/home/olle/Documents/University Courses/Protein Prediction II/ppcs2-project-master/dataset'\n",
    "data_file = data_dir + '/subloc_k3_s5_eukaryota.1682.fa_1516057206692442.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "df = pd.read_csv(data_file, sep=',')\n",
    "print(df.shape)\n",
    "\n",
    "#create ML ready data\n",
    "X,y = handle_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and tune optimál model\n",
    "best_model,X_test, y_test = return_opt_model(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save model for future use\n",
    "joblib.dump(best_model, 'rf_model_03_eukaryota')\n",
    "\n",
    "# Load model\n",
    "clf2 = joblib.load('rf_model_03_eukaryota')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get metrics for presentation\n",
    "overall_acc, sd_acc, cnf_matrix, random_acc, naive_acc = presentation_metric(clf2, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Results Archea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/home/olle/Documents/University Courses/Protein Prediction II/ppcs2-project-master/dataset'\n",
    "data_file = data_dir + '/subloc_k3_s5_archaea.59.fa_1516096802270404.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load data\n",
    "df = pd.read_csv(data_file, sep=',')\n",
    "print(df.shape)\n",
    "\n",
    "#create ML ready data\n",
    "X,y = handle_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train and tune optimál model\n",
    "best_model,X_test, y_test = return_opt_model(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save model for future use\n",
    "joblib.dump(best_model, 'rf_model_03_archea')\n",
    "\n",
    "# Load model\n",
    "clf2 = joblib.load('rf_model_03_archea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get metrics for presentation\n",
    "overall_acc, sd_acc, cnf_matrix, random_acc, naive_acc = presentation_metric(clf2, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_acc,sd_acc,cnf_matrix,random_acc,naive_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Results Bacteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/home/olle/Documents/University Courses/Protein Prediction II/ppcs2-project-master/dataset'\n",
    "data_file = data_dir + '/subloc_k3_s5_bacteria.479.fa_1516097171505748.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load data\n",
    "df = pd.read_csv(data_file, sep=',')\n",
    "print(df.shape)\n",
    "\n",
    "#create ML ready data\n",
    "X,y = handle_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train and tune optimál model\n",
    "best_model,X_test, y_test = return_opt_model(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save model for future use\n",
    "joblib.dump(best_model, 'rf_model_03_bacteria')\n",
    "\n",
    "# Load model\n",
    "clf2 = joblib.load('rf_model_03_bacteria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get metrics for presentation\n",
    "overall_acc, sd_acc, cnf_matrix, random_acc, naive_acc = presentation_metric(clf2, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "overall_acc,sd_acc,cnf_matrix,random_acc,naive_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
